{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "1b310624-3201-4523-aae0-17145dedfd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "from torch.nn import functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import vocab\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import string\n",
    "\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "7a6ae866-8b3c-48e9-a58f-ea78597b1fb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5ee90c80-1f88-4e71-aeea-e0fca7111f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/arturo/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/arturo/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6fc40df-e080-47db-8a34-c5964bb6ba40",
   "metadata": {},
   "source": [
    "# Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "14cf3de7-5739-4b68-b834-02a76699aae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fake Samples: 18784, True Samples: 17133\n"
     ]
    }
   ],
   "source": [
    "df_test_like = pd.read_csv(\"en/en_test_like_file.csv\")\n",
    "df_fake = pd.read_csv(\"en/en_train_fake.csv\")\n",
    "df_true = pd.read_csv(\"en/en_train_true.csv\")\n",
    "\n",
    "print(f\"Fake Samples: {len(df_fake)}, True Samples: {len(df_true)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5ccbb47d-744a-45cc-90c9-126ec862ff47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create labels for true(1) and fake(0)\n",
    "df_fake['labels']=0\n",
    "df_true['labels']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c1b4d208-fb4b-439e-93ca-480c59c4179a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_fake,df_true], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b42d42d1-d799-4d48-88f3-3599badca415",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['title'] + ' ' + df['text']\n",
    "df = df[['text','labels']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "99d26e14-da0a-4ff7-87da-8750ca8003d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[VIDEO] #BlackLivesMatter Terrorists Storm Dar...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FLASHBACK: TRUMP PLANS STRATEGY Against North ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SHARIA LAWYER: Why Muslims are Less Likely to ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Republican Governor Helped Kill 11 Elderly Pe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NY Teacher Gives Assignment To High School Kid...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35912</th>\n",
       "      <td>Nigeria says U.S. agrees delayed $593 million ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35913</th>\n",
       "      <td>'Nearly man' Ramaphosa edges closer to South A...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35914</th>\n",
       "      <td>Trump says sought Flynn's resignation over sta...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35915</th>\n",
       "      <td>Republican tax plan would deal financial hit t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35916</th>\n",
       "      <td>U.N. refugee commissioner says Australia must ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35917 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  labels\n",
       "0      [VIDEO] #BlackLivesMatter Terrorists Storm Dar...       0\n",
       "1      FLASHBACK: TRUMP PLANS STRATEGY Against North ...       0\n",
       "2      SHARIA LAWYER: Why Muslims are Less Likely to ...       0\n",
       "3       Republican Governor Helped Kill 11 Elderly Pe...       0\n",
       "4      NY Teacher Gives Assignment To High School Kid...       0\n",
       "...                                                  ...     ...\n",
       "35912  Nigeria says U.S. agrees delayed $593 million ...       1\n",
       "35913  'Nearly man' Ramaphosa edges closer to South A...       1\n",
       "35914  Trump says sought Flynn's resignation over sta...       1\n",
       "35915  Republican tax plan would deal financial hit t...       1\n",
       "35916  U.N. refugee commissioner says Australia must ...       1\n",
       "\n",
       "[35917 rows x 2 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4030f089-e11d-4e9c-9731-59872fc44965",
   "metadata": {},
   "source": [
    "# Text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e4c30599-809e-45ee-a6ae-bb77b4f60d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess(text):\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    filtered_tokens = [word for word in tokens if word not in stop_words and word.isalpha()]\n",
    "    return ' '.join(filtered_tokens)\n",
    "\n",
    "# Apply preprocessing\n",
    "df['text'] = df['text'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f9f896dd-a771-4fb5-9cfe-8b822f42a464",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>video blacklivesmatter terrorists storm dartmo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>flashback trump plans strategy north korea int...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sharia lawyer muslims less likely integrate we...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>republican governor helped kill elderly people...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ny teacher gives assignment high school kids c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35912</th>\n",
       "      <td>nigeria says agrees delayed million fighter pl...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35913</th>\n",
       "      <td>man ramaphosa edges closer south africa top jo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35914</th>\n",
       "      <td>trump says sought flynn resignation statements...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35915</th>\n",
       "      <td>republican tax plan would deal financial hit u...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35916</th>\n",
       "      <td>refugee commissioner says australia must stop ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35917 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  labels\n",
       "0      video blacklivesmatter terrorists storm dartmo...       0\n",
       "1      flashback trump plans strategy north korea int...       0\n",
       "2      sharia lawyer muslims less likely integrate we...       0\n",
       "3      republican governor helped kill elderly people...       0\n",
       "4      ny teacher gives assignment high school kids c...       0\n",
       "...                                                  ...     ...\n",
       "35912  nigeria says agrees delayed million fighter pl...       1\n",
       "35913  man ramaphosa edges closer south africa top jo...       1\n",
       "35914  trump says sought flynn resignation statements...       1\n",
       "35915  republican tax plan would deal financial hit u...       1\n",
       "35916  refugee commissioner says australia must stop ...       1\n",
       "\n",
       "[35917 rows x 2 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c3ccfe-16c2-4e47-a308-7ef4680d50cb",
   "metadata": {},
   "source": [
    "# Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "86f3587a-d164-49e2-9d69-0e6c21160f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = get_tokenizer('basic_english') # nltk tokenizer\n",
    "\n",
    "# Build vocabulary\n",
    "# count all unique tokens in a dataset and build a vocabulary from that\n",
    "# keeps vocabularies smaller and domain specific\n",
    "def build_vocab(dataset: pd.DataFrame):\n",
    "    counter = Counter()\n",
    "    for i, row in dataset.iterrows():\n",
    "        counter.update(tokenizer(row[\"text\"]))\n",
    "    v = vocab(counter, specials=['<unk>', '<pad>'])\n",
    "    v.set_default_index(v['<unk>'])\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "40e175a2-f3f0-42cb-90af-7c2c6d4ba9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = torch.Generator().manual_seed(42)\n",
    "\n",
    "train_dataset, test_dataset, val_dataset = torch.utils.data.random_split(df, [0.7, 0.15, 0.15], generator=generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "58c870af-a1d3-4c9e-8ef1-3c48977dd633",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df.iloc[train_dataset.indices]\n",
    "test_df = df.iloc[test_dataset.indices]\n",
    "val_df = df.iloc[val_dataset.indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "09d05cba-4530-4698-845c-5f296f961323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47.97 % True on Train\n",
      "48.31 % True on Test\n",
      "45.85 % True on Val\n"
     ]
    }
   ],
   "source": [
    "print(f\"{100*train_df['labels'].sum()/len(train_df):.2f} % True on Train\")\n",
    "print(f\"{100*test_df['labels'].sum()/len(test_df):.2f} % True on Test\")\n",
    "print(f\"{100*val_df['labels'].sum()/len(val_df):.2f} % True on Val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6a38e3fa-a57f-4a03-ad06-d01b942c8a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fakenews_vocab = build_vocab(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c51de558-53c9-4505-b307-9fd727f7acd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FakeNewsDataset(Dataset):\n",
    "    def __init__(self,dataframe,vocab):\n",
    "        self.dataframe = dataframe\n",
    "        self.vocab = vocab\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        text = tokenizer(self.dataframe.iloc[idx]['text'])\n",
    "        label = int(self.dataframe.iloc[idx]['labels'])\n",
    "        return [self.vocab[token] for token in text], label\n",
    "\n",
    "train_dataset = FakeNewsDataset(train_df,fakenews_vocab)\n",
    "test_dataset = FakeNewsDataset(test_df,fakenews_vocab)\n",
    "val_dataset = FakeNewsDataset(val_df,fakenews_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "ad0e0b2e-b79b-449d-bc9b-a2f140141961",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_batch(batch):\n",
    "    label_list, text_list, lengths = [], [], []\n",
    "    for _text, _label in batch:\n",
    "        label_list.append(_label) # store label for sample\n",
    "        processed_text = torch.tensor(_text, dtype=torch.int64) # tokens to tensor\n",
    "        text_list.append(processed_text) # store tensor\n",
    "        lengths.append(len(processed_text)) # store length of tensor\n",
    "    label_list = torch.tensor(label_list, dtype=torch.int64) # labels to tensor\n",
    "    # tensors of different size in same batch -> pad shorter ones\n",
    "    text_list = pad_sequence(text_list,\n",
    "                             batch_first=True,\n",
    "                             padding_value=fakenews_vocab['<pad>'])\n",
    "    lengths = torch.tensor(lengths, dtype=torch.int64) # lengths to tensor\n",
    "    return text_list, label_list, lengths\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_batch)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_batch)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802d847c-4946-412c-a6e2-cf0b4b589274",
   "metadata": {},
   "source": [
    "# Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "b8b8bdf0-b964-42e6-b321-5abf945c23b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, output_dim, num_layers):\n",
    "        super(LSTMModel,self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self,x, text_lengths):\n",
    "        embedded = self.embedding(x)\n",
    "        packed_embedding = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        packed_output, (hidden,_) = self.lstm(packed_embedding)\n",
    "        hidden = hidden[-1,:,:]\n",
    "        z = self.fc(hidden)\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "f5d57615-bcef-4be7-8d4a-e92321e42b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(fakenews_vocab)\n",
    "embed_dim = 100\n",
    "hidden_dim = 256\n",
    "output_dim = 2\n",
    "num_layers = 2\n",
    "\n",
    "learning_rate = 1e-3\n",
    "\n",
    "model = LSTMModel(vocab_size, embed_dim, hidden_dim, output_dim, num_layers)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "4eccdad7-2f79-47a7-9f49-f4d546137f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(n_epochs, model, train_loader, val_loader, optimizer, criterion):\n",
    "    accuracies = []\n",
    "\n",
    "    model.to(device)\n",
    "    \n",
    "    for i in tqdm(range(n_epochs)):\n",
    "        for x_train, y_train, lens in train_loader:\n",
    "            x_train, y_train = x_train.to(device), y_train.to(device)\n",
    "            lens = lens.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            z_train = model(x_train, text_lengths=lens)\n",
    "            loss = criterion(z_train, y_train)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        correct = 0\n",
    "        with torch.no_grad():\n",
    "            for x_val, y_val, lens in val_loader:\n",
    "                x_val, y_val = x_val.to(device), y_val.to(device)\n",
    "                lens = lens.to(device)\n",
    "                \n",
    "                z_val = model(x_val, text_lengths=lens)\n",
    "                val_loss = criterion(z_val, y_val)\n",
    "                \n",
    "                _,y_pred = torch.max(z_val.data,1)\n",
    "                correct += (y_pred == y_val).sum().item()Test Accuracy: 99.92 %\n",
    "\n",
    "        accuracy = correct/len(val_loader.dataset)\n",
    "        print(f\"Val Acc: {accuracy * 100:.2f}%\")\n",
    "        accuracies.append(accuracy)\n",
    "\n",
    "    return accuracies\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "561df9c0-baf8-42c3-9c50-dd183af21b0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "786"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "542e85db-5df5-4fe3-8612-dcbc9a2b94a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|██▏                                         | 1/20 [01:12<22:52, 72.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 99.78%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████▍                                       | 2/20 [02:24<21:44, 72.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 99.72%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|██████▌                                     | 3/20 [03:37<20:32, 72.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 96.60%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████▊                                   | 4/20 [04:50<19:21, 72.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 99.68%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|███████████                                 | 5/20 [06:02<18:07, 72.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 99.74%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|█████████████▏                              | 6/20 [07:15<16:56, 72.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 99.74%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███████████████▍                            | 7/20 [08:27<15:43, 72.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 99.68%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████▌                          | 8/20 [09:40<14:32, 72.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 99.72%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|███████████████████▊                        | 9/20 [10:53<13:18, 72.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 99.65%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████▌                     | 10/20 [12:05<12:05, 72.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 99.68%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|███████████████████████▋                   | 11/20 [13:18<10:53, 72.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 99.76%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████▊                 | 12/20 [14:31<09:41, 72.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 99.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|███████████████████████████▉               | 13/20 [15:43<08:28, 72.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 99.81%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████████████████████████████             | 14/20 [16:56<07:15, 72.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 99.76%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|████████████████████████████████▎          | 15/20 [18:08<06:03, 72.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 99.81%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████████▍        | 16/20 [19:21<04:50, 72.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 99.81%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████████████████████████████████▌      | 17/20 [20:34<03:38, 72.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 99.81%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|██████████████████████████████████████▋    | 18/20 [21:47<02:25, 72.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 99.81%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|████████████████████████████████████████▊  | 19/20 [23:00<01:12, 72.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 99.81%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [24:15<00:00, 72.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 99.81%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 20\n",
    "\n",
    "accuracies = train_model(n_epochs,model,train_loader,val_loader,optimizer,criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "3239027f-2670-431e-8dac-35b11dc01e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(\n",
    "    model,\n",
    "    test_loader\n",
    "):\n",
    "    model.to(device)\n",
    "    correct = 0\n",
    "    preds = []\n",
    "    trues = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x_test, y_test, lens in test_loader:\n",
    "            x_test, y_test = x_test.to(device), y_test.to(device)\n",
    "            lens = lens.to(device)\n",
    "                \n",
    "            z_test = model(x_test, text_lengths=lens)\n",
    "            _,y_pred = torch.max(z_test.data,1)\n",
    "            correct += (y_pred == y_test).sum().item()\n",
    "            preds.extend(y_pred.cpu().numpy())\n",
    "            trues.extend(y_test.cpu().numpy())\n",
    "\n",
    "    accuracy = correct/len(test_loader.dataset)\n",
    "\n",
    "    return accuracy, preds, trues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "69cefe84-a74d-41d8-819e-886c9c277146",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy = evaluate_model(model,test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "49dbcf56-7e5d-409b-871b-5a0f29ccd56a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 99.85 %\n"
     ]
    }
   ],
   "source": [
    "plt.plot(100*np.array(accuracies), label='Accuracy')\n",
    "plt.title(\"Validation Performance\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"%\")\n",
    "plt.xticks(5*np.array(range(11)))\n",
    "plt.legend()\n",
    "\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "2f4e34bd-21fb-4dfe-a39c-8608b876ab45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fake Samples: 23481, True Samples: 21417\n"
     ]
    }
   ],
   "source": [
    "df_fake_new = pd.read_csv(\"new/Fake.csv\")\n",
    "df_true_new = pd.read_csv(\"new/True.csv\")\n",
    "\n",
    "print(f\"Fake Samples: {len(df_fake_new)}, True Samples: {len(df_true_new)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "7716ebab-babc-4dcb-9a79-2da3553b42a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create labels for true(1) and fake(0)\n",
    "df_fake_new['labels']=0\n",
    "df_true_new['labels']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "e45199fd-9ece-459f-bfed-fe55f4899937",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Donald Trump Sends Out Embarrassing New Year’...</td>\n",
       "      <td>Donald Trump just couldn t wish all Americans ...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 31, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Drunk Bragging Trump Staffer Started Russian ...</td>\n",
       "      <td>House Intelligence Committee Chairman Devin Nu...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 31, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sheriff David Clarke Becomes An Internet Joke...</td>\n",
       "      <td>On Friday, it was revealed that former Milwauk...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 30, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trump Is So Obsessed He Even Has Obama’s Name...</td>\n",
       "      <td>On Christmas day, Donald Trump announced that ...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 29, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pope Francis Just Called Out Donald Trump Dur...</td>\n",
       "      <td>Pope Francis used his annual Christmas Day mes...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 25, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23476</th>\n",
       "      <td>McPain: John McCain Furious That Iran Treated ...</td>\n",
       "      <td>21st Century Wire says As 21WIRE reported earl...</td>\n",
       "      <td>Middle-east</td>\n",
       "      <td>January 16, 2016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23477</th>\n",
       "      <td>JUSTICE? Yahoo Settles E-mail Privacy Class-ac...</td>\n",
       "      <td>21st Century Wire says It s a familiar theme. ...</td>\n",
       "      <td>Middle-east</td>\n",
       "      <td>January 16, 2016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23478</th>\n",
       "      <td>Sunnistan: US and Allied ‘Safe Zone’ Plan to T...</td>\n",
       "      <td>Patrick Henningsen  21st Century WireRemember ...</td>\n",
       "      <td>Middle-east</td>\n",
       "      <td>January 15, 2016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23479</th>\n",
       "      <td>How to Blow $700 Million: Al Jazeera America F...</td>\n",
       "      <td>21st Century Wire says Al Jazeera America will...</td>\n",
       "      <td>Middle-east</td>\n",
       "      <td>January 14, 2016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23480</th>\n",
       "      <td>10 U.S. Navy Sailors Held by Iranian Military ...</td>\n",
       "      <td>21st Century Wire says As 21WIRE predicted in ...</td>\n",
       "      <td>Middle-east</td>\n",
       "      <td>January 12, 2016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23481 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "0       Donald Trump Sends Out Embarrassing New Year’...   \n",
       "1       Drunk Bragging Trump Staffer Started Russian ...   \n",
       "2       Sheriff David Clarke Becomes An Internet Joke...   \n",
       "3       Trump Is So Obsessed He Even Has Obama’s Name...   \n",
       "4       Pope Francis Just Called Out Donald Trump Dur...   \n",
       "...                                                  ...   \n",
       "23476  McPain: John McCain Furious That Iran Treated ...   \n",
       "23477  JUSTICE? Yahoo Settles E-mail Privacy Class-ac...   \n",
       "23478  Sunnistan: US and Allied ‘Safe Zone’ Plan to T...   \n",
       "23479  How to Blow $700 Million: Al Jazeera America F...   \n",
       "23480  10 U.S. Navy Sailors Held by Iranian Military ...   \n",
       "\n",
       "                                                    text      subject  \\\n",
       "0      Donald Trump just couldn t wish all Americans ...         News   \n",
       "1      House Intelligence Committee Chairman Devin Nu...         News   \n",
       "2      On Friday, it was revealed that former Milwauk...         News   \n",
       "3      On Christmas day, Donald Trump announced that ...         News   \n",
       "4      Pope Francis used his annual Christmas Day mes...         News   \n",
       "...                                                  ...          ...   \n",
       "23476  21st Century Wire says As 21WIRE reported earl...  Middle-east   \n",
       "23477  21st Century Wire says It s a familiar theme. ...  Middle-east   \n",
       "23478  Patrick Henningsen  21st Century WireRemember ...  Middle-east   \n",
       "23479  21st Century Wire says Al Jazeera America will...  Middle-east   \n",
       "23480  21st Century Wire says As 21WIRE predicted in ...  Middle-east   \n",
       "\n",
       "                    date  labels  \n",
       "0      December 31, 2017       0  \n",
       "1      December 31, 2017       0  \n",
       "2      December 30, 2017       0  \n",
       "3      December 29, 2017       0  \n",
       "4      December 25, 2017       0  \n",
       "...                  ...     ...  \n",
       "23476   January 16, 2016       0  \n",
       "23477   January 16, 2016       0  \n",
       "23478   January 15, 2016       0  \n",
       "23479   January 14, 2016       0  \n",
       "23480   January 12, 2016       0  \n",
       "\n",
       "[23481 rows x 5 columns]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fake_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "09502e26-13c2-48c9-9da7-78e6a5d6f84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = pd.concat([df_fake_new,df_true_new], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "36f14e81-8843-4dde-a97c-bd08cc974e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new['text'] = df_new['title'] + ' ' + df_new['text']\n",
    "df_new = df_new[['text','labels']]\n",
    "df_new['text'] = df_new['text'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "5aa58a0d-1319-4cab-91f9-ac697d146c03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>donald trump sends embarrassing new year eve m...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>drunk bragging trump staffer started russian c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sheriff david clarke becomes internet joke thr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>trump obsessed even obama name coded website i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pope francis called donald trump christmas spe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44893</th>\n",
       "      <td>committed nato backs new approach afghanistan ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44894</th>\n",
       "      <td>lexisnexis withdrew two products chinese marke...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44895</th>\n",
       "      <td>minsk cultural hub becomes authorities minsk r...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44896</th>\n",
       "      <td>vatican upbeat possibility pope francis visiti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44897</th>\n",
       "      <td>indonesia buy billion worth russian jets jakar...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44898 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  labels\n",
       "0      donald trump sends embarrassing new year eve m...       0\n",
       "1      drunk bragging trump staffer started russian c...       0\n",
       "2      sheriff david clarke becomes internet joke thr...       0\n",
       "3      trump obsessed even obama name coded website i...       0\n",
       "4      pope francis called donald trump christmas spe...       0\n",
       "...                                                  ...     ...\n",
       "44893  committed nato backs new approach afghanistan ...       1\n",
       "44894  lexisnexis withdrew two products chinese marke...       1\n",
       "44895  minsk cultural hub becomes authorities minsk r...       1\n",
       "44896  vatican upbeat possibility pope francis visiti...       1\n",
       "44897  indonesia buy billion worth russian jets jakar...       1\n",
       "\n",
       "[44898 rows x 2 columns]"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "e02148a2-8e3f-4cae-8cec-e5c7ba386989",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test_dataset = FakeNewsDataset(df_new,fakenews_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "ae2ec973-a02e-4739-9fe1-51307f0463a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "new_test_loader = DataLoader(new_test_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "f2165027-6293-4645-a777-cec55b00e65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy, preds, trues = evaluate_model(model,new_test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "36a79bdc-819f-4c97-ace3-53c4e42525b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 99.92 %\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "5f5b4774-9364-405d-8e49-ce53bdc0b123",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[23465,    16],\n",
       "       [   21, 21396]])"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(trues,preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7dce42-5c38-4657-ad1e-d8628a906596",
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
